# S3
- what is S3
- Buckets and objects
- Uploading objects to Buckets
- S3 bucket versioning
- S3 Bucket encryption
- S3 bucket Lifecycle policies
- S3 bucket best practices

## What is S3
- Amazon S3 (Simple Storage Service) is an object storage service that offers industry-leading scalability,   
   ```data availability, security, and performance```
- Amazon S3 allows people to store ```objects (files) in “buckets” (directories)```
- Buckets must have a ```globally unique name``` (across all region all accounts)
- Buckets are defined at the region level
- S3 looks like a global service but buckets are created in a region

## Usecases of S3 bucket 
- Backup and Storage
- Disaster Recovery
- Archive
- Hybrid Cloud Storage
- Media Hosting
- Datalake and Big data analysis
- Software delivery
- Static website

## Here are some key reasons why businesses and developers choose to use AWS S3 bucket:-
- `Scalability`::- AWS S3 provides virtually limitless scalability, enabling users to store and retrieve any amount of data without worrying about capacity constraints.
- `Durability` ::- S3 is designed to deliver 99.999999999% (11 nines) durability for objects, ensuring high data reliability. It replicates data across multiple facilities and geographic regions, reducing the risk of data loss and ensuring data availability even in the event of hardware failures, natural disasters, or other disruptions
- `Security` ::There are security controls that is designed for the data at rest, data at transit and even have security controls to access the data. t allows users to implement security best practices and compliance requirements, ensuring the protection of sensitive data stored within S3 buckets.
- `Versatility` :: S3 supports a wide range of use cases, such as data backup and recovery, media storage and distribution, hosting static websites, application data storage, and big data analytics. Its versatility makes it suitable for various industries, including e-commerce, media and entertainment, healthcare, finance, and more
- Ease of Use and Integration :: AWS S3 integrates seamlessly with other AWS services and third-party applications, allowing for easy data transfer and integration into existing workflows

## S3 Object.
- Objects (files) have a key-value
- The key is the full path: s3://my-bucket/folder1/folder2/file.txt
- Object values are the content of body
- Max. object size is 5TB
- if uploading more than 5GB, we must use “multi-part upload”


## Naming convention of S3 bucket.
- S3 looks like a global service but buckets are created in a region
- 3–63 character long
- not an IP
- must start with lowercase letter or number

### LAB 1:- Create a S3 bucket and upload object via UI
### LAB 2:- Upload object via awscli

## S3 verioning
Versioning is a means of keeping the multiple forms of an object in the same S3 bucket. Versioning can be used to retrieve, preserve and restore every version of an object in S3 bucket

### Versioing pointer
- It stores all versions of an object (including all writes and even if you delete an object)
- It is a great backup tool.
- Once the versioning enabled, it cannot be disabled, only suspended.
- It is integrated with lifecycle rules.
- Versioning's MFA Delete capability uses multi-factor authentication that can be used to provide the additional layer of security






📌 Bucket Naming: Choose a unique and meaningful name for your S3 bucket. Bucket names are globally unique across all of AWS, so make sure to select a name that is not already in use.

📌 Data Classification: Clearly define the sensitivity of your data and implement appropriate access controls. Use AWS Identity and Access Management (IAM) policies to restrict access based on roles and permissions.

📌 Access Control Lists (ACLs) vs. Bucket Policies: You can control access to your S3 bucket using either Access Control Lists (ACLs) or Bucket Policies. It’s recommended to use IAM policies and bucket policies for more granular and manageable access control.

📌 Versioning: Enable versioning for your S3 buckets to maintain a historical record of changes to objects. This can be helpful in cases of accidental deletions or overwrites.

📌 Data Encryption: Implement data encryption both in transit and at rest. Use SSL/TLS for data in transit and server-side encryption (SSE) for data at rest. SSE options include SSE-S3, SSE-KMS, and SSE-C.

📌 Data Lifecycle: Set up data lifecycle policies to automatically transition objects to different storage classes (e.g., from Standard to Glacier) or to delete them after a specific period. This helps optimize costs and storage.

📌 Cross-Region Replication: Replicate your S3 objects across different AWS regions for disaster recovery and high availability. Cross-Region Replication (CRR) can be configured to automatically replicate objects to a target bucket in another region.

📌 Logging and Monitoring: Enable access logging for your S3 bucket to track who is accessing your objects. Additionally, use Amazon CloudWatch to monitor and set up alarms for various S3 metrics.

📌 Pre-Signed URLs: If you need to grant temporary access to specific objects without making them public, you can generate pre-signed URLs. These URLs grant time-limited access to the object based on the permissions you specify.

📌 Cost Optimization: Regularly review your storage usage and access patterns to optimize costs. Use S3 storage classes such as Standard, Intelligent-Tiering, and Glacier to match your data’s access frequency and durability requirements.
