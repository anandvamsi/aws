# S3
- what is S3
- Buckets and objects
- Uploading objects to Buckets
- S3 bucket versioning
- S3 Bucket encryption
- S3 bucket Lifecycle policies
- S3 bucket best practices

## What is S3
- Amazon S3 (Simple Storage Service) is an object storage service that offers industry-leading scalability,   
   ```data availability, security, and performance```
- Amazon S3 allows people to store ```objects (files) in ‚Äúbuckets‚Äù (directories)```
- Buckets must have a ```globally unique name``` (across all region all accounts)
- Buckets are defined at the region level
- S3 looks like a global service but buckets are created in a region

## Usecases of S3 bucket 
- Backup and Storage
- Disaster Recovery
- Archive
- Hybrid Cloud Storage
- Media Hosting
- Datalake and Big data analysis
- Software delivery
- Static website

## Here are some key reasons why businesses and developers choose to use AWS S3 bucket:-
- `Scalability`::- AWS S3 provides virtually limitless scalability, enabling users to store and retrieve any amount of data without worrying about capacity constraints.
- `Durability` ::- S3 is designed to deliver 99.999999999% (11 nines) durability for objects, ensuring high data reliability. It replicates data across multiple facilities and geographic regions, reducing the risk of data loss and ensuring data availability even in the event of hardware failures, natural disasters, or other disruptions
- `Security` ::There are security controls that is designed for the data at rest, data at transit and even have security controls to access the data. t allows users to implement security best practices and compliance requirements, ensuring the protection of sensitive data stored within S3 buckets.
- `Versatility` :: S3 supports a wide range of use cases, such as data backup and recovery, media storage and distribution, hosting static websites, application data storage, and big data analytics. Its versatility makes it suitable for various industries, including e-commerce, media and entertainment, healthcare, finance, and more
- Ease of Use and Integration :: AWS S3 integrates seamlessly with other AWS services and third-party applications, allowing for easy data transfer and integration into existing workflows

## S3 Object.
- Objects (files) have a key-value
- The key is the full path: s3://my-bucket/folder1/folder2/file.txt
- Object values are the content of body
- Max. object size is 5TB
- if uploading more than 5GB, we must use ‚Äúmulti-part upload‚Äù


## Naming convention of S3 bucket.
- S3 looks like a global service but buckets are created in a region
- 3‚Äì63 character long
- not an IP
- must start with lowercase letter or number

### LAB 1:- Create a S3 bucket and upload object via UI
### LAB 2:- Upload object via awscli

## S3 verioning
Versioning is a means of keeping the multiple forms of an object in the same S3 bucket. Versioning can be used to retrieve, preserve and restore every version of an object in S3 bucket


## S3 Life cycle policies

 <img src="S3-LifeCycle.png" width="600">


Amazon S3 has different storage classes. When we upload a file into S3 we can choose which storage class is apt for our files. There are 6 types of storage classes
- Standard
- Intelligent Tiering
- Standard Infrequent Access
- Glacier
- Glacier Deep Archive.

The Storage classes are classified into different categories based on
- Storage cost
- Object Durability
- Object Availbility
- Frequency of Access

### `S3 Standard` 
- S3 have 99.99% availability and 99.99999999999% durability that means The objects in this storage class are highly available and the chance of losing that file is very very rare.
- We can store files which we use regularly.
- S3 is the most expensive storage standard among all others.
- The data is stored in multiple location.

### `S3 Standard Infrequent Access (IA)`
- This is used to store data which is accessed less frequently but need quick access when needed.
- The objects in this storage have 99.90% availability and 99.99999999999% object durability in different locations.
- It is less expensive than standard storage.
- Amazon charges a retrieval fee to retrieve the data.

### `S3 One Zone Infrequently Access:`
- This is a low-cost storage option compared to S3 standard storage and Standard Infrequent access.
- This is used to store infrequently accessed non-critical data or data which can be regenerated if lost because this storage class stores the data only in one facility.
- The objects in this storage have 99.5% availability and 99.99999999999% object durability in a single availability zone.
- Less expensive than standard storage classes.
  
### `Glacier and Glacier Deep archive :`
- Glacier is used for data archiving
- The data retrieval time can be from minutes to hours.
- Glacier Deep Archive is also used for data archiving but the retrieval time for Deep archive is 12 hours.
- The data durability is 99.99999999999%

### `Intelligent Tiering:`
- It monitors your data access patterns and moves the data to different storage classes accordingly.
- The objects in this storage have 99.90% availability and 99.99999999999% object durability in different locations.
- Less expensive than standard storage classes.

### `Glacier and Glacier Deep archive:` 
- Glacier is used for data archiving
- This is the cheapest storage S3 service.
- The data retrieval time can be from minutes to hours.
- Glacier Deep Archive is also used for data archiving but the retrieval time for Deep archive is 12 hours.
- The data durability is 99.99999999999%
  
  
### Usecases of Lifecycle policy
- Application server, database logs are stored in s3 but logs may not require after a few weeks or months, in this case, 
you can delete the objects automatically by applying an expiration action.

- Frequency of access requirement of an organization‚Äôs documents (financial, media, employee data) Some documents are frequently accessed, but after a few days or months, they are infrequently accessed. After some time, organization may need to archive them as documents are not used anymore but must be retained for regulatory compliance, in this case, you can use transition action.





### Versioing pointers
- It stores all versions of an object (including all writes and even if you delete an object)
- It is a great backup tool.
- Once the versioning enabled, it cannot be disabled, only suspended.
- It is integrated with lifecycle rules.
- Versioning's MFA Delete capability uses multi-factor authentication that can be used to provide the additional layer of security.







### S3 Best practices 

üìå Bucket Naming: Choose a unique and meaningful name for your S3 bucket. Bucket names are globally unique across all of AWS, so make sure to select a name that is not already in use.

üìå Data Classification: Clearly define the sensitivity of your data and implement appropriate access controls. Use AWS Identity and Access Management (IAM) policies to restrict access based on roles and permissions.

üìå Access Control Lists (ACLs) vs. Bucket Policies: You can control access to your S3 bucket using either Access Control Lists (ACLs) or Bucket Policies. It‚Äôs recommended to use IAM policies and bucket policies for more granular and manageable access control.

üìå Versioning: Enable versioning for your S3 buckets to maintain a historical record of changes to objects. This can be helpful in cases of accidental deletions or overwrites.

üìå Data Encryption: Implement data encryption both in transit and at rest. Use SSL/TLS for data in transit and server-side encryption (SSE) for data at rest. SSE options include SSE-S3, SSE-KMS, and SSE-C.

üìå Data Lifecycle: Set up data lifecycle policies to automatically transition objects to different storage classes (e.g., from Standard to Glacier) or to delete them after a specific period. This helps optimize costs and storage.

üìå Cross-Region Replication: Replicate your S3 objects across different AWS regions for disaster recovery and high availability. Cross-Region Replication (CRR) can be configured to automatically replicate objects to a target bucket in another region.

üìå Logging and Monitoring: Enable access logging for your S3 bucket to track who is accessing your objects. Additionally, use Amazon CloudWatch to monitor and set up alarms for various S3 metrics.

üìå Pre-Signed URLs: If you need to grant temporary access to specific objects without making them public, you can generate pre-signed URLs. These URLs grant time-limited access to the object based on the permissions you specify.

üìå Cost Optimization: Regularly review your storage usage and access patterns to optimize costs. Use S3 storage classes such as Standard, Intelligent-Tiering, and Glacier to match your data‚Äôs access frequency and durability requirements.
